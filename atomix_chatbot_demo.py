# -*- coding: utf-8 -*-
"""Atomix Chatbot Demo

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11fUwh4xKCWKNth0QKsAlFG32GLOcS-gt
"""

import streamlit as st
import requests
import time

# --- CONFIGURATION ---
# PASTE YOUR N8N WEBHOOK URL HERE
N8N_WEBHOOK_URL = "https://n8n.foosignia.com/webhook/chat"

# --- UI SETUP ---
st.set_page_config(page_title="Atomix AI Support", page_icon="ðŸ¤–", layout="wide")

# Custom CSS to match your Atomix Blue branding
st.markdown("""
<style>
    .stApp { background-color: #f5f7f9; }
    .stChatInput { border-radius: 10px; }
    div[data-testid="stChatMessage"] {
        background-color: white;
        border-radius: 15px;
        padding: 10px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
    }
    h1 { color: #0066cc; }
</style>
""", unsafe_allow_html=True)

# Header
col1, col2 = st.columns([1, 5])
with col1:
    st.image("https://img.icons8.com/color/96/robot-2.png", width=60) # Placeholder logo
with col2:
    st.title("Atomix Intelligent Q&A")
    st.caption("Industrial Support System | T-Series / AGV / Pallet Shuttle")

# --- CHAT LOGIC ---

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Hello! I am the Atomix AI. I have access to the T-Series manuals. Ask me about error codes, maintenance, or technical specs."}
    ]

# Display chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Chat Input
if prompt := st.chat_input("Describe the issue or ask a technical question..."):
    # 1. Display user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. Call n8n Backend
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("Searching knowledge base...")

        try:
            # Send POST request to n8n
            response = requests.post(
                N8N_WEBHOOK_URL,
                json={"chatInput": prompt} # Matches the input n8n expects
            )

            if response.status_code == 200:
                data = response.json()
                # Extract answer - adjust key based on your n8n output
                bot_response = data.get("answer", data.get("text", "I found some info but couldn't parse it."))
                message_placeholder.markdown(bot_response)
                st.session_state.messages.append({"role": "assistant", "content": bot_response})
            else:
                message_placeholder.error(f"Error connecting to Brain: {response.status_code}")

        except Exception as e:
            message_placeholder.error(f"Connection Failed: {e}")